{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484f6fd6",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8841751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to be imported\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest,chi2,f_classif,mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,OneHotEncoder,Normalizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9696f4e",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2274320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"C:/Users/AnmitY/OneDrive/Desktop/training_data.csv\")\n",
    "target=pd.read_csv(\"C:/Users/AnmitY/OneDrive/Desktop/training_data_targets.csv\",names=['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63a49a",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16b947",
   "metadata": {},
   "source": [
    "## taking care of empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4492ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gendera</th>\n",
       "      <th>BMI</th>\n",
       "      <th>hypertensive</th>\n",
       "      <th>atrialfibrillation</th>\n",
       "      <th>CHD with no MI</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>deficiencyanemias</th>\n",
       "      <th>depression</th>\n",
       "      <th>Hyperlipemia</th>\n",
       "      <th>...</th>\n",
       "      <th>Blood sodium</th>\n",
       "      <th>Blood calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Anion gap</th>\n",
       "      <th>Magnesium ion</th>\n",
       "      <th>PH</th>\n",
       "      <th>Bicarbonate</th>\n",
       "      <th>Lactic acid</th>\n",
       "      <th>PCO2</th>\n",
       "      <th>EF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>21.551321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.230769</td>\n",
       "      <td>8.712500</td>\n",
       "      <td>95.846154</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>1.841667</td>\n",
       "      <td>7.310000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.600</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>53.018931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>132.600000</td>\n",
       "      <td>7.475000</td>\n",
       "      <td>104.800000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>7.383333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>28.187883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.666667</td>\n",
       "      <td>8.257143</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>2.085714</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>1.775</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.486719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.250000</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>2.225000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>31.416667</td>\n",
       "      <td>1.600</td>\n",
       "      <td>43.416667</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>28.187883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>141.533333</td>\n",
       "      <td>8.390909</td>\n",
       "      <td>109.066667</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>2.446154</td>\n",
       "      <td>7.328889</td>\n",
       "      <td>16.266667</td>\n",
       "      <td>1.800</td>\n",
       "      <td>28.625000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>33.669081</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.666667</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>97.400000</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>2.328571</td>\n",
       "      <td>7.441250</td>\n",
       "      <td>31.066667</td>\n",
       "      <td>1.500</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>24.040864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.142857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>107.571429</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>2.157143</td>\n",
       "      <td>7.390000</td>\n",
       "      <td>30.285714</td>\n",
       "      <td>2.000</td>\n",
       "      <td>57.428571</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>13.673625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>139.125000</td>\n",
       "      <td>9.337500</td>\n",
       "      <td>100.125000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.862500</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>25.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>9.655556</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>28.416667</td>\n",
       "      <td>1.700</td>\n",
       "      <td>43.416667</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>56.132848</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>139.666667</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>95.416667</td>\n",
       "      <td>11.916667</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>7.365000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.025</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gendera        BMI  hypertensive  atrialfibrillation  \\\n",
       "0      83        2  21.551321             0                   0   \n",
       "1      72        2  53.018931             1                   1   \n",
       "2      74        2  28.187883             1                   1   \n",
       "3      44        1  28.486719             0                   0   \n",
       "4      89        1  28.187883             1                   1   \n",
       "...   ...      ...        ...           ...                 ...   \n",
       "1053   68        1  33.669081             1                   1   \n",
       "1054   85        1  24.040864             1                   1   \n",
       "1055   63        2  13.673625             1                   1   \n",
       "1056   89        1  25.312500             0                   0   \n",
       "1057   58        1  56.132848             1                   1   \n",
       "\n",
       "      CHD with no MI  diabetes  deficiencyanemias  depression  Hyperlipemia  \\\n",
       "0                  0         0                  0           0             0   \n",
       "1                  0         0                  0           0             1   \n",
       "2                  0         0                  0           0             0   \n",
       "3                  0         0                  0           0             0   \n",
       "4                  0         1                  0           0             1   \n",
       "...              ...       ...                ...         ...           ...   \n",
       "1053               0         1                  0           0             0   \n",
       "1054               0         0                  0           0             0   \n",
       "1055               0         0                  0           1             1   \n",
       "1056               1         1                  1           0             1   \n",
       "1057               0         1                  1           0             1   \n",
       "\n",
       "      ...  Blood sodium  Blood calcium    Chloride  Anion gap  Magnesium ion  \\\n",
       "0     ...    133.230769       8.712500   95.846154  14.615385       1.841667   \n",
       "1     ...    132.600000       7.475000  104.800000  11.800000       2.160000   \n",
       "2     ...    138.666667       8.257143  104.833333  14.166667       2.085714   \n",
       "3     ...    139.250000       8.714286   97.333333  14.583333       2.225000   \n",
       "4     ...    141.533333       8.390909  109.066667  20.800000       2.446154   \n",
       "...   ...           ...            ...         ...        ...            ...   \n",
       "1053  ...    135.666667       7.857143   97.400000  11.266667       2.328571   \n",
       "1054  ...    144.142857       9.371429  107.571429  10.142857       2.157143   \n",
       "1055  ...    139.125000       9.337500  100.125000  12.000000       1.862500   \n",
       "1056  ...    139.000000       9.655556   99.916667  15.500000       2.133333   \n",
       "1057  ...    139.666667       8.777778   95.416667  11.916667       2.170000   \n",
       "\n",
       "            PH  Bicarbonate  Lactic acid       PCO2  EF  \n",
       "0     7.310000    27.000000        1.600  50.000000  50  \n",
       "1     7.383333    20.000000        1.200  32.000000  55  \n",
       "2     7.400000    23.500000        1.775  37.625000  75  \n",
       "3     7.380000    31.416667        1.600  43.416667  30  \n",
       "4     7.328889    16.266667        1.800  28.625000  25  \n",
       "...        ...          ...          ...        ...  ..  \n",
       "1053  7.441250    31.066667        1.500  47.000000  25  \n",
       "1054  7.390000    30.285714        2.000  57.428571  55  \n",
       "1055  7.320000    31.500000        1.200  67.500000  50  \n",
       "1056  7.380000    28.416667        1.700  43.416667  50  \n",
       "1057  7.365000    37.000000        1.025  70.666667  55  \n",
       "\n",
       "[1058 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "median=data.median()\n",
    "data=data.fillna(median)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b163ac",
   "metadata": {},
   "source": [
    "## encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e46d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender=np.array(data.gendera).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e809e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#One hot encoder\n",
    "ohd=OneHotEncoder()\n",
    "gender=ohd.fit_transform(gender).toarray().astype(int)\n",
    "gender=pd.DataFrame(gender)\n",
    "add=ohd.fit_transform(data.iloc[:,3:12]).toarray().astype(int)\n",
    "data.drop(columns=data.columns[3:12],inplace=True)\n",
    "add=pd.DataFrame(add)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3dd85bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "0     0  1\n",
       "1     0  1\n",
       "2     0  1\n",
       "3     1  0\n",
       "4     1  0\n",
       "...  .. ..\n",
       "1053  1  0\n",
       "1054  1  0\n",
       "1055  0  1\n",
       "1056  1  0\n",
       "1057  1  0\n",
       "\n",
       "[1058 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a85c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heart rate</th>\n",
       "      <th>Systolic blood pressure</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Respiratory rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>SP O2</th>\n",
       "      <th>Urine output</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>...</th>\n",
       "      <th>Blood sodium</th>\n",
       "      <th>Blood calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Anion gap</th>\n",
       "      <th>Magnesium ion</th>\n",
       "      <th>PH</th>\n",
       "      <th>Bicarbonate</th>\n",
       "      <th>Lactic acid</th>\n",
       "      <th>PCO2</th>\n",
       "      <th>EF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>21.551321</td>\n",
       "      <td>66.320000</td>\n",
       "      <td>111.160000</td>\n",
       "      <td>50.440000</td>\n",
       "      <td>18.440000</td>\n",
       "      <td>35.796296</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>31.587500</td>\n",
       "      <td>...</td>\n",
       "      <td>133.230769</td>\n",
       "      <td>8.712500</td>\n",
       "      <td>95.846154</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>1.841667</td>\n",
       "      <td>7.310000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.600</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>53.018931</td>\n",
       "      <td>119.515152</td>\n",
       "      <td>101.620690</td>\n",
       "      <td>53.862069</td>\n",
       "      <td>23.272727</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>92.606061</td>\n",
       "      <td>790.0</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>132.600000</td>\n",
       "      <td>7.475000</td>\n",
       "      <td>104.800000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>7.383333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>28.187883</td>\n",
       "      <td>65.727273</td>\n",
       "      <td>115.705882</td>\n",
       "      <td>55.970588</td>\n",
       "      <td>16.307692</td>\n",
       "      <td>37.317460</td>\n",
       "      <td>98.971429</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>138.666667</td>\n",
       "      <td>8.257143</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>2.085714</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>1.775</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>28.486719</td>\n",
       "      <td>98.269231</td>\n",
       "      <td>136.880000</td>\n",
       "      <td>84.720000</td>\n",
       "      <td>22.307692</td>\n",
       "      <td>36.819444</td>\n",
       "      <td>97.925926</td>\n",
       "      <td>6056.0</td>\n",
       "      <td>40.887500</td>\n",
       "      <td>...</td>\n",
       "      <td>139.250000</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>2.225000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>31.416667</td>\n",
       "      <td>1.600</td>\n",
       "      <td>43.416667</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>28.187883</td>\n",
       "      <td>90.666667</td>\n",
       "      <td>99.275862</td>\n",
       "      <td>52.379310</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>36.571429</td>\n",
       "      <td>94.166667</td>\n",
       "      <td>814.0</td>\n",
       "      <td>33.668421</td>\n",
       "      <td>...</td>\n",
       "      <td>141.533333</td>\n",
       "      <td>8.390909</td>\n",
       "      <td>109.066667</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>2.446154</td>\n",
       "      <td>7.328889</td>\n",
       "      <td>16.266667</td>\n",
       "      <td>1.800</td>\n",
       "      <td>28.625000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>68</td>\n",
       "      <td>33.669081</td>\n",
       "      <td>85.718750</td>\n",
       "      <td>120.548387</td>\n",
       "      <td>56.548387</td>\n",
       "      <td>19.189189</td>\n",
       "      <td>37.574074</td>\n",
       "      <td>95.156250</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>28.420000</td>\n",
       "      <td>...</td>\n",
       "      <td>135.666667</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>97.400000</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>2.328571</td>\n",
       "      <td>7.441250</td>\n",
       "      <td>31.066667</td>\n",
       "      <td>1.500</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>85</td>\n",
       "      <td>24.040864</td>\n",
       "      <td>66.758621</td>\n",
       "      <td>112.515152</td>\n",
       "      <td>59.878788</td>\n",
       "      <td>25.714286</td>\n",
       "      <td>37.180555</td>\n",
       "      <td>96.482759</td>\n",
       "      <td>937.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>144.142857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>107.571429</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>2.157143</td>\n",
       "      <td>7.390000</td>\n",
       "      <td>30.285714</td>\n",
       "      <td>2.000</td>\n",
       "      <td>57.428571</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>63</td>\n",
       "      <td>13.673625</td>\n",
       "      <td>108.807692</td>\n",
       "      <td>137.695652</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>20.730769</td>\n",
       "      <td>36.730159</td>\n",
       "      <td>95.791667</td>\n",
       "      <td>715.0</td>\n",
       "      <td>31.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>139.125000</td>\n",
       "      <td>9.337500</td>\n",
       "      <td>100.125000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.862500</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>89</td>\n",
       "      <td>25.312500</td>\n",
       "      <td>70.217391</td>\n",
       "      <td>110.956522</td>\n",
       "      <td>50.608696</td>\n",
       "      <td>24.565217</td>\n",
       "      <td>36.518519</td>\n",
       "      <td>95.826087</td>\n",
       "      <td>3855.0</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>9.655556</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>28.416667</td>\n",
       "      <td>1.700</td>\n",
       "      <td>43.416667</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>58</td>\n",
       "      <td>56.132848</td>\n",
       "      <td>87.960000</td>\n",
       "      <td>148.250000</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>20.880000</td>\n",
       "      <td>36.577778</td>\n",
       "      <td>89.720000</td>\n",
       "      <td>6875.0</td>\n",
       "      <td>27.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>139.666667</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>95.416667</td>\n",
       "      <td>11.916667</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>7.365000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.025</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age        BMI  heart rate  Systolic blood pressure  \\\n",
       "0      83  21.551321   66.320000               111.160000   \n",
       "1      72  53.018931  119.515152               101.620690   \n",
       "2      74  28.187883   65.727273               115.705882   \n",
       "3      44  28.486719   98.269231               136.880000   \n",
       "4      89  28.187883   90.666667                99.275862   \n",
       "...   ...        ...         ...                      ...   \n",
       "1053   68  33.669081   85.718750               120.548387   \n",
       "1054   85  24.040864   66.758621               112.515152   \n",
       "1055   63  13.673625  108.807692               137.695652   \n",
       "1056   89  25.312500   70.217391               110.956522   \n",
       "1057   58  56.132848   87.960000               148.250000   \n",
       "\n",
       "      Diastolic blood pressure  Respiratory rate  temperature      SP O2  \\\n",
       "0                    50.440000         18.440000    35.796296  95.000000   \n",
       "1                    53.862069         23.272727    36.111111  92.606061   \n",
       "2                    55.970588         16.307692    37.317460  98.971429   \n",
       "3                    84.720000         22.307692    36.819444  97.925926   \n",
       "4                    52.379310         23.666667    36.571429  94.166667   \n",
       "...                        ...               ...          ...        ...   \n",
       "1053                 56.548387         19.189189    37.574074  95.156250   \n",
       "1054                 59.878788         25.714286    37.180555  96.482759   \n",
       "1055                 77.000000         20.730769    36.730159  95.791667   \n",
       "1056                 50.608696         24.565217    36.518519  95.826087   \n",
       "1057                 65.750000         20.880000    36.577778  89.720000   \n",
       "\n",
       "      Urine output  hematocrit  ...  Blood sodium  Blood calcium    Chloride  \\\n",
       "0           1845.0   31.587500  ...    133.230769       8.712500   95.846154   \n",
       "1            790.0   25.600000  ...    132.600000       7.475000  104.800000   \n",
       "2           3245.0   30.100000  ...    138.666667       8.257143  104.833333   \n",
       "3           6056.0   40.887500  ...    139.250000       8.714286   97.333333   \n",
       "4            814.0   33.668421  ...    141.533333       8.390909  109.066667   \n",
       "...            ...         ...  ...           ...            ...         ...   \n",
       "1053        2140.0   28.420000  ...    135.666667       7.857143   97.400000   \n",
       "1054         937.0   35.500000  ...    144.142857       9.371429  107.571429   \n",
       "1055         715.0   31.857143  ...    139.125000       9.337500  100.125000   \n",
       "1056        3855.0   30.010000  ...    139.000000       9.655556   99.916667   \n",
       "1057        6875.0   27.187500  ...    139.666667       8.777778   95.416667   \n",
       "\n",
       "      Anion gap  Magnesium ion        PH  Bicarbonate  Lactic acid       PCO2  \\\n",
       "0     14.615385       1.841667  7.310000    27.000000        1.600  50.000000   \n",
       "1     11.800000       2.160000  7.383333    20.000000        1.200  32.000000   \n",
       "2     14.166667       2.085714  7.400000    23.500000        1.775  37.625000   \n",
       "3     14.583333       2.225000  7.380000    31.416667        1.600  43.416667   \n",
       "4     20.800000       2.446154  7.328889    16.266667        1.800  28.625000   \n",
       "...         ...            ...       ...          ...          ...        ...   \n",
       "1053  11.266667       2.328571  7.441250    31.066667        1.500  47.000000   \n",
       "1054  10.142857       2.157143  7.390000    30.285714        2.000  57.428571   \n",
       "1055  12.000000       1.862500  7.320000    31.500000        1.200  67.500000   \n",
       "1056  15.500000       2.133333  7.380000    28.416667        1.700  43.416667   \n",
       "1057  11.916667       2.170000  7.365000    37.000000        1.025  70.666667   \n",
       "\n",
       "      EF  \n",
       "0     50  \n",
       "1     55  \n",
       "2     75  \n",
       "3     30  \n",
       "4     25  \n",
       "...   ..  \n",
       "1053  25  \n",
       "1054  55  \n",
       "1055  50  \n",
       "1056  50  \n",
       "1057  55  \n",
       "\n",
       "[1058 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=data.columns[1],inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfbe8e",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2adb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "skb=SelectKBest(mutual_info_classif,k=34).fit(data,target)\n",
    "data=skb.transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd487c",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d7431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n=Normalizer(norm='l2',copy=True)\n",
    "data=n.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca1d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=Normalizer(norm='l2',copy=True)\n",
    "data=n.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c50262e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff9f55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.142246</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.076740</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.359595</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.695767</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.212441</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.032814</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.047425</td>\n",
       "      <td>0.460569</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>0.215021</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.017976</td>\n",
       "      <td>0.723172</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.012518</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.978386</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.001662  0.005113  0.001422  0.002760  0.007324  0.142246  0.002435   \n",
       "1     0.005150  0.011610  0.002261  0.003508  0.008996  0.076740  0.002487   \n",
       "2     0.003124  0.007284  0.001807  0.004135  0.010968  0.359595  0.003336   \n",
       "3     0.003273  0.011290  0.002563  0.004230  0.011251  0.695767  0.004698   \n",
       "4     0.000715  0.002300  0.000600  0.000928  0.002389  0.020649  0.000854   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1053  0.003342  0.008509  0.001905  0.003730  0.009446  0.212441  0.002821   \n",
       "1054  0.011817  0.032814  0.012639  0.018276  0.047425  0.460569  0.017450   \n",
       "1055  0.004112  0.032722  0.006234  0.011046  0.028807  0.215021  0.009580   \n",
       "1056  0.004748  0.013172  0.004608  0.006851  0.017976  0.723172  0.005630   \n",
       "1057  0.007988  0.012518  0.002971  0.005205  0.012768  0.978386  0.003869   \n",
       "\n",
       "            7         8         9   ...  10  11  12  13  14  15  16  17  0   \\\n",
       "0     0.000286  0.002245  0.002642  ...   1   0   1   0   1   0   1   0   0   \n",
       "1     0.000283  0.002961  0.003371  ...   1   0   0   1   1   0   1   0   0   \n",
       "2     0.000398  0.003267  0.003914  ...   1   0   1   0   0   1   1   0   0   \n",
       "3     0.000522  0.003521  0.003912  ...   1   0   1   0   1   0   1   0   1   \n",
       "4     0.000100  0.000745  0.000873  ...   1   0   0   1   0   1   1   0   1   \n",
       "...        ...       ...       ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "1053  0.000320  0.002847  0.003205  ...   1   0   1   0   0   1   1   0   1   \n",
       "1054  0.001821  0.015860  0.016557  ...   1   0   1   0   1   0   1   0   1   \n",
       "1055  0.001125  0.007969  0.009361  ...   0   1   0   1   1   0   1   0   0   \n",
       "1056  0.000642  0.005872  0.006697  ...   1   0   0   1   0   1   1   0   1   \n",
       "1057  0.000448  0.003864  0.004476  ...   1   0   0   1   1   0   1   0   1   \n",
       "\n",
       "      1   \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "...   ..  \n",
       "1053   0  \n",
       "1054   0  \n",
       "1055   1  \n",
       "1056   0  \n",
       "1057   0  \n",
       "\n",
       "[1058 rows x 54 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.concat([data,add,gender],axis=1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af2130",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44745b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=29)\n",
    "data1=pca.fit_transform(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f24e5",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57973a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1=np.array(data1)\n",
    "target=np.array(target)\n",
    "skf=StratifiedKFold(n_splits=4)\n",
    "for train, test in skf.split(data1,target):\n",
    "        x_train = data1[train]\n",
    "        y_train = target[train]\n",
    "        x_test = data1[test]\n",
    "        y_test = target[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9527e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_train=y_train.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50d4651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.484192</td>\n",
       "      <td>0.412429</td>\n",
       "      <td>-0.042304</td>\n",
       "      <td>-0.012682</td>\n",
       "      <td>-0.182420</td>\n",
       "      <td>-0.125992</td>\n",
       "      <td>0.714396</td>\n",
       "      <td>-0.352635</td>\n",
       "      <td>0.091583</td>\n",
       "      <td>-0.235211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>-0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.131136</td>\n",
       "      <td>-0.587514</td>\n",
       "      <td>-1.382819</td>\n",
       "      <td>-0.654831</td>\n",
       "      <td>0.483481</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.052628</td>\n",
       "      <td>-0.200991</td>\n",
       "      <td>-0.018410</td>\n",
       "      <td>-0.182258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001419</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033229</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>-0.909986</td>\n",
       "      <td>0.713164</td>\n",
       "      <td>-0.093830</td>\n",
       "      <td>-1.114615</td>\n",
       "      <td>0.134254</td>\n",
       "      <td>-0.027402</td>\n",
       "      <td>-0.088606</td>\n",
       "      <td>0.143608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>-0.001945</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.291322</td>\n",
       "      <td>-0.302402</td>\n",
       "      <td>1.124986</td>\n",
       "      <td>-0.107424</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.387745</td>\n",
       "      <td>-0.187890</td>\n",
       "      <td>-0.109764</td>\n",
       "      <td>-0.111031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.597092</td>\n",
       "      <td>-1.093030</td>\n",
       "      <td>-0.029838</td>\n",
       "      <td>-0.113048</td>\n",
       "      <td>-0.243533</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.354364</td>\n",
       "      <td>-0.142787</td>\n",
       "      <td>-0.105471</td>\n",
       "      <td>-0.172707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>-1.099082</td>\n",
       "      <td>-1.259191</td>\n",
       "      <td>0.278699</td>\n",
       "      <td>0.492832</td>\n",
       "      <td>-0.077318</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.229949</td>\n",
       "      <td>-0.131948</td>\n",
       "      <td>-0.065386</td>\n",
       "      <td>-0.219097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>-0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>-0.603500</td>\n",
       "      <td>-1.211825</td>\n",
       "      <td>0.127055</td>\n",
       "      <td>-0.046983</td>\n",
       "      <td>0.025339</td>\n",
       "      <td>-0.175227</td>\n",
       "      <td>-0.813410</td>\n",
       "      <td>0.122013</td>\n",
       "      <td>-0.225572</td>\n",
       "      <td>0.052370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.000691</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>-0.000392</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.003063</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.161485</td>\n",
       "      <td>-0.244375</td>\n",
       "      <td>-0.516589</td>\n",
       "      <td>1.026075</td>\n",
       "      <td>-1.299073</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>1.019737</td>\n",
       "      <td>-0.266962</td>\n",
       "      <td>-0.003858</td>\n",
       "      <td>0.129254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>-0.726916</td>\n",
       "      <td>1.166907</td>\n",
       "      <td>-0.091838</td>\n",
       "      <td>0.092082</td>\n",
       "      <td>0.467731</td>\n",
       "      <td>-0.169031</td>\n",
       "      <td>-0.905015</td>\n",
       "      <td>-0.145757</td>\n",
       "      <td>-0.189574</td>\n",
       "      <td>0.194915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>-0.968833</td>\n",
       "      <td>0.437249</td>\n",
       "      <td>-0.241476</td>\n",
       "      <td>-0.503542</td>\n",
       "      <td>-0.057355</td>\n",
       "      <td>-0.804523</td>\n",
       "      <td>-0.288925</td>\n",
       "      <td>-0.133721</td>\n",
       "      <td>-0.004105</td>\n",
       "      <td>-0.112006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>-0.003487</td>\n",
       "      <td>-0.001332</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>-0.001110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -1.484192  0.412429 -0.042304 -0.012682 -0.182420 -0.125992  0.714396   \n",
       "1   -0.131136 -0.587514 -1.382819 -0.654831  0.483481  0.042810  0.052628   \n",
       "2   -0.033229 -0.492199 -0.909986  0.713164 -0.093830 -1.114615  0.134254   \n",
       "3   -1.291322 -0.302402  1.124986 -0.107424  0.021760  0.127314  0.387745   \n",
       "4    1.597092 -1.093030 -0.029838 -0.113048 -0.243533  0.006098  0.354364   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "789 -1.099082 -1.259191  0.278699  0.492832 -0.077318  0.479399  0.229949   \n",
       "790 -0.603500 -1.211825  0.127055 -0.046983  0.025339 -0.175227 -0.813410   \n",
       "791  0.161485 -0.244375 -0.516589  1.026075 -1.299073  0.029788  1.019737   \n",
       "792 -0.726916  1.166907 -0.091838  0.092082  0.467731 -0.169031 -0.905015   \n",
       "793 -0.968833  0.437249 -0.241476 -0.503542 -0.057355 -0.804523 -0.288925   \n",
       "\n",
       "           7         8         9   ...        19        20        21  \\\n",
       "0   -0.352635  0.091583 -0.235211  ...  0.001722  0.000418 -0.000569   \n",
       "1   -0.200991 -0.018410 -0.182258  ... -0.001419 -0.000337  0.002425   \n",
       "2   -0.027402 -0.088606  0.143608  ...  0.001712 -0.001945  0.000571   \n",
       "3   -0.187890 -0.109764 -0.111031  ... -0.000951  0.001429 -0.000655   \n",
       "4   -0.142787 -0.105471 -0.172707  ...  0.000341 -0.000229  0.000043   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "789 -0.131948 -0.065386 -0.219097  ...  0.002228  0.000667  0.001561   \n",
       "790  0.122013 -0.225572  0.052370  ...  0.001855 -0.001124 -0.000691   \n",
       "791 -0.266962 -0.003858  0.129254  ...  0.001333  0.000330 -0.000433   \n",
       "792 -0.145757 -0.189574  0.194915  ... -0.000591 -0.000126  0.008545   \n",
       "793 -0.133721 -0.004105 -0.112006  ... -0.001004 -0.000729 -0.003487   \n",
       "\n",
       "           22        23        24        25        26        27        28  \n",
       "0   -0.000424 -0.000003  0.000183 -0.000061 -0.000002 -0.000324 -0.000150  \n",
       "1   -0.000522 -0.001008 -0.000897  0.000312 -0.000670  0.000061  0.000072  \n",
       "2   -0.000115  0.000573 -0.000252 -0.000469 -0.000430  0.000029 -0.000126  \n",
       "3    0.000932 -0.000665  0.000111  0.000187  0.000131 -0.000415 -0.000295  \n",
       "4   -0.000191 -0.000335  0.000172  0.000046  0.000003  0.000118  0.000058  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "789  0.001597 -0.000976 -0.001129  0.001119  0.001428  0.001274 -0.000066  \n",
       "790  0.000493 -0.000392  0.001221  0.000617 -0.000712 -0.003063  0.000611  \n",
       "791  0.000279  0.000142  0.000169 -0.000171  0.000056  0.000370  0.000105  \n",
       "792  0.000504 -0.001766 -0.000080 -0.000673 -0.001407  0.000632  0.000665  \n",
       "793 -0.001332  0.000318  0.000858 -0.000807  0.001846  0.000606 -0.001110  \n",
       "\n",
       "[794 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.DataFrame(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3742d5",
   "metadata": {},
   "source": [
    "## Getting Parameters for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de80f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for Parameters\n",
    "\n",
    "param_grid2={'n_neighbors':[5,6,7,10,12,15,16,17,18,20,23,24,34,56],'weights':['uniform', 'distance'],'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],'leaf_size':[5,6,7,8,9,10,11],'p':[1,2,3]}#knn\n",
    "param_grid3={'kernel':['sigmoid','liner','poly', 'rbf'],'C':[0.1,1,5,10,15,20,30,40,100],'gamma':['scale', 'auto'],'coef0':[0,1,2,3],'shrinking':[True,False],'decision_function_shape':['ovo','ovr']}#SVC\n",
    "param_grid4={'activation':['identity', 'logistic', 'tanh', 'relu'],'solver':[ 'sgd', 'adam'],'max_iter':[200,400,800,1000],'alpha':[0.0001,0.0005,0.001,0.005,0.01]}#MLP classifier\n",
    "param_grid5={'penalty':['l1', 'l2', 'elasticnet', 'None'],'solver':['lbfgs' 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],'max_iter':[100,200,400,800,1000,2000,1500],'C':[0.1,0.001,0.0001,0.005,2],'class_weight':['dict','balanced']}#logarithmicRegression\n",
    "\n",
    "param_grid7={'n_estimators':[20,100,200],'criterion':['gini', 'entropy','log_loss'],'max_features':['sqrt', 'log2', 'None'],'ccp_alpha':[0.02,0.01,0.05],'max_depth':[50,100,200]}#RandomForestClassifier\n",
    "param_grid8={'var_smoothing':[1e-10,1e-9,1e-8,1e-7,1e-6]}#GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1fbb4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.55560314        nan ... 0.53497117        nan 0.54282849]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 5,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv2=GridSearchCV(estimator=KNeighborsClassifier(),param_grid=param_grid2,cv=6,n_jobs=-1,scoring='f1_macro')\n",
    "gv2.fit(x_train,y_train)\n",
    "gv2.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f041ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1728 fits failed out of a total of 6912.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "209 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'linear', 'poly', 'precomputed', 'rbf', 'sigmoid'} or a callable. Got 'liner' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "417 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'rbf', 'precomputed', 'linear', 'poly', 'sigmoid'} or a callable. Got 'liner' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "287 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'sigmoid', 'linear', 'precomputed', 'rbf', 'poly'} or a callable. Got 'liner' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "213 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'rbf', 'poly', 'linear', 'sigmoid', 'precomputed'} or a callable. Got 'liner' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "272 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'rbf', 'sigmoid', 'poly'} or a callable. Got 'liner' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "176 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'rbf', 'sigmoid', 'linear', 'poly', 'precomputed'} or a callable. Got 'liner' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "154 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'linear', 'poly', 'rbf', 'precomputed', 'sigmoid'} or a callable. Got 'liner' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.46387505 0.46387505        nan ... 0.47456661 0.46242128 0.46242128]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 40,\n",
       " 'coef0': 0,\n",
       " 'decision_function_shape': 'ovo',\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'sigmoid',\n",
       " 'shrinking': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv3=GridSearchCV(estimator=SVC(),param_grid=param_grid3,cv=6,n_jobs=-1,scoring='f1_macro')\n",
    "gv3.fit(x_train,y_train)\n",
    "gv3.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d30515e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'alpha': 0.0001, 'max_iter': 1000, 'solver': 'adam'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv4=GridSearchCV(estimator=MLPClassifier(),param_grid=param_grid4,cv=6,n_jobs=-1,scoring='f1_macro')\n",
    "gv4.fit(x_train,y_train)\n",
    "gv4.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74ff2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "7350 fits failed out of a total of 8400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got 'dict' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'saga', 'newton-cg', 'sag', 'newton-cholesky', 'lbfgs', 'liblinear'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "76 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'lbfgs', 'newton-cg', 'newton-cholesky', 'liblinear', 'sag', 'saga'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "88 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'newton-cg', 'saga', 'sag', 'liblinear', 'newton-cholesky', 'lbfgs'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1178, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "92 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "82 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'saga', 'newton-cholesky', 'sag', 'newton-cg', 'liblinear', 'lbfgs'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "78 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'newton-cholesky', 'saga', 'newton-cg', 'liblinear', 'sag', 'lbfgs'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "92 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'lbfgs', 'newton-cg', 'sag', 'newton-cholesky', 'saga', 'liblinear'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "140 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'l1', 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "154 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'none' (deprecated), 'l1', 'l2'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'newton-cg', 'newton-cholesky', 'liblinear', 'saga', 'sag', 'lbfgs'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l2', 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'newton-cg', 'lbfgs', 'liblinear', 'saga', 'sag', 'newton-cholesky'}. Got 'lbfgsliblinear' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "186 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l1', 'l2', 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'none' (deprecated), 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "78 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 2,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 100,\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv5=GridSearchCV(estimator=LogisticRegression(),param_grid=param_grid5,cv=6,n_jobs=-1,scoring='f1_macro')\n",
    "gv5.fit(x_train,y_train)\n",
    "gv5.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcdbe252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "2592 fits failed out of a total of 7776.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1533 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1059 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.46387505 0.46387505 0.46387505 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.01,\n",
       " 'criterion': 'log_loss',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 15}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv7=GridSearchCV(estimator=RandomForestClassifier(),param_grid=param_grid7,cv=6,n_jobs=-1,scoring='f1_macro')\n",
    "gv7.fit(x_train,y_train)\n",
    "gv7.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b653c65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-07}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv8=GridSearchCV(estimator=GaussianNB(),param_grid=param_grid8,cv=6,n_jobs=-1,scoring='f1_macro')\n",
    "gv8.fit(x_train,y_train)\n",
    "gv8.best_params_\n",
    "#{'var_smoothing': 1e-07}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51fab238",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB(var_smoothing=1e-07)\n",
    "svc=SVC(C=40,coef0=0,decision_function_shape='ovo',gamma='scale',kernel='sigmoid',shrinking= True)#updated \n",
    "knn=KNeighborsClassifier(algorithm='auto',leaf_size=5,n_neighbors= 5,p= 2,weights= 'distance')#updated\n",
    "mlp=MLPClassifier(activation= 'relu',alpha=0.0001, max_iter= 1000, solver= 'adam')\n",
    "lr=LogisticRegression(C= 2,class_weight= 'balanced',max_iter= 100,penalty= 'l2',solver='newton-cg')\n",
    "rfc=RandomForestClassifier(ccp_alpha= 0.01,criterion= 'entropy',max_depth= 100,max_features= 'sqrt',n_estimators= 100,random_state=42)#updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4ff3f",
   "metadata": {},
   "source": [
    "## Fitting the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70473866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnmitY\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=1e-07)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=1e-07)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=1e-07)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train)\n",
    "rfc.fit(x_train,y_train)\n",
    "knn.fit(x_train,y_train)\n",
    "mlp.fit(x_train,y_train)\n",
    "gnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f72c5fc",
   "metadata": {},
   "source": [
    "## Predicting on x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd92dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict1=lr.predict(x_test)\n",
    "y_predict2=svc.predict(x_test)\n",
    "y_predict4=rfc.predict(x_test)\n",
    "y_predict5=knn.predict(x_test)\n",
    "y_predict6=mlp.predict(x_test)\n",
    "y_predict7=gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04716b61",
   "metadata": {},
   "source": [
    "# Checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb8295aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.6498538011695907\n",
      "0.5773438973778533\n",
      "0.5640263449320977\n",
      "[[157  14]\n",
      " [ 71  22]]\n",
      "0.678030303030303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       171\n",
      "           1       0.61      0.24      0.34        93\n",
      "\n",
      "    accuracy                           0.68       264\n",
      "   macro avg       0.65      0.58      0.56       264\n",
      "weighted avg       0.66      0.68      0.63       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(precision_score(y_predict1,y_test,average='macro'))\n",
    "print(recall_score(y_predict1,y_test,average='macro'))\n",
    "print(f1_score(y_predict1,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict1,y_test))\n",
    "print(accuracy_score(y_predict1,y_test))\n",
    "print(classification_report(y_predict1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59343bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine for Classification\n",
      "0.48026315789473684\n",
      "0.47757164613041675\n",
      "0.4786155987956098\n",
      "[[200  33]\n",
      " [ 28   3]]\n",
      "0.7689393939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       233\n",
      "           1       0.08      0.10      0.09        31\n",
      "\n",
      "    accuracy                           0.77       264\n",
      "   macro avg       0.48      0.48      0.48       264\n",
      "weighted avg       0.78      0.77      0.78       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine for Classification\")\n",
    "print(precision_score(y_predict2,y_test,average='macro'))\n",
    "print(recall_score(y_predict2,y_test,average='macro'))\n",
    "print(f1_score(y_predict2,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict2,y_test))\n",
    "print(accuracy_score(y_predict2,y_test))\n",
    "print(classification_report(y_predict2,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0677520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "0.5116959064327485\n",
      "0.6832061068702291\n",
      "0.48958109559613316\n",
      "[[227  35]\n",
      " [  1   1]]\n",
      "0.8636363636363636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93       262\n",
      "           1       0.03      0.50      0.05         2\n",
      "\n",
      "    accuracy                           0.86       264\n",
      "   macro avg       0.51      0.68      0.49       264\n",
      "weighted avg       0.99      0.86      0.92       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier')\n",
    "print(precision_score(y_predict4,y_test,average='macro'))\n",
    "print(recall_score(y_predict4,y_test,average='macro'))\n",
    "print(f1_score(y_predict4,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict4,y_test))\n",
    "print(accuracy_score(y_predict4,y_test))\n",
    "print(classification_report(y_predict4,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf21813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "0.5021929824561403\n",
      "0.5035273368606702\n",
      "0.4984914515588334\n",
      "[[210  33]\n",
      " [ 18   3]]\n",
      "0.8068181818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       243\n",
      "           1       0.08      0.14      0.11        21\n",
      "\n",
      "    accuracy                           0.81       264\n",
      "   macro avg       0.50      0.50      0.50       264\n",
      "weighted avg       0.85      0.81      0.83       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('KNN')\n",
    "print(precision_score(y_predict5,y_test,average='macro'))\n",
    "print(recall_score(y_predict5,y_test,average='macro'))\n",
    "print(f1_score(y_predict5,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict5,y_test))\n",
    "print(accuracy_score(y_predict5,y_test))\n",
    "print(classification_report(y_predict5,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2d7426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "0.5343567251461988\n",
      "0.5552616108171664\n",
      "0.5378254553581405\n",
      "[[212  31]\n",
      " [ 16   5]]\n",
      "0.821969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       243\n",
      "           1       0.14      0.24      0.18        21\n",
      "\n",
      "    accuracy                           0.82       264\n",
      "   macro avg       0.53      0.56      0.54       264\n",
      "weighted avg       0.87      0.82      0.84       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MLP')\n",
    "print(precision_score(y_predict6,y_test,average='macro'))\n",
    "print(recall_score(y_predict6,y_test,average='macro'))\n",
    "print(f1_score(y_predict6,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict6,y_test))\n",
    "print(accuracy_score(y_predict6,y_test))\n",
    "print(classification_report(y_predict6,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9dbd0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB\n",
      "0.5687134502923977\n",
      "0.6155737704918033\n",
      "0.5805084745762712\n",
      "[[215  29]\n",
      " [ 13   7]]\n",
      "0.8409090909090909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       244\n",
      "           1       0.19      0.35      0.25        20\n",
      "\n",
      "    accuracy                           0.84       264\n",
      "   macro avg       0.57      0.62      0.58       264\n",
      "weighted avg       0.89      0.84      0.86       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian NB')\n",
    "print(precision_score(y_predict7,y_test,average='macro'))\n",
    "print(recall_score(y_predict7,y_test,average='macro'))\n",
    "print(f1_score(y_predict7,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict7,y_test))\n",
    "print(accuracy_score(y_predict7,y_test))\n",
    "print(classification_report(y_predict7,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c6a92",
   "metadata": {},
   "source": [
    "# Applying adaboost on logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90998246",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb2=AdaBoostClassifier(LogisticRegression(C= 2,class_weight= 'balanced',max_iter= 100,penalty= 'l2',solver='newton-cg'),algorithm= 'SAMME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e77e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5497076023391813\n",
      "0.6165714285714285\n",
      "0.5581589958158996\n",
      "[[219  31]\n",
      " [  9   5]]\n",
      "0.8484848484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       250\n",
      "           1       0.14      0.36      0.20        14\n",
      "\n",
      "    accuracy                           0.85       264\n",
      "   macro avg       0.55      0.62      0.56       264\n",
      "weighted avg       0.92      0.85      0.88       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adb2.fit(x_train,y_train)\n",
    "y_predict8=adb2.predict(x_test)\n",
    "print(precision_score(y_predict8,y_test,average='macro'))\n",
    "print(recall_score(y_predict8,y_test,average='macro'))\n",
    "print(f1_score(y_predict8,y_test,average='macro'))\n",
    "print(confusion_matrix(y_predict8,y_test))\n",
    "print(accuracy_score(y_predict8,y_test))\n",
    "print(classification_report(y_predict8,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b30ac",
   "metadata": {},
   "source": [
    "# Testing the data on adifferent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d0f27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"C:/Users/AnmitY/OneDrive/Desktop/test_data.csv\")\n",
    "\n",
    "median=test.median()\n",
    "test=test.fillna(median)\n",
    "gender1=np.array(test.gendera).reshape(-1,1)\n",
    "#One hot encoder\n",
    "ohd=OneHotEncoder()\n",
    "gender1=ohd.fit_transform(gender1).toarray().astype(int)\n",
    "gender1=pd.DataFrame(gender1)\n",
    "add=ohd.fit_transform(test.iloc[:,3:12]).toarray().astype(int)\n",
    "test.drop(columns=test.columns[3:12],inplace=True)\n",
    "add=pd.DataFrame(add)\n",
    "test.drop(columns=test.columns[1],inplace=True)\n",
    "test=skb.transform(test)\n",
    "#n=Normalizer(norm='l2',copy=True)\n",
    "test=n.transform(test)\n",
    "test=pd.DataFrame(test)\n",
    "test1=pd.concat([test,add,gender1],axis=1)\n",
    "pca=PCA(n_components=29)\n",
    "test1=pca.fit_transform(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "365de4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9f678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
